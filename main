import time
from selenium.common.exceptions import TimeoutException
from selenium import webdriver
from bs4 import BeautifulSoup
from selenium.webdriver import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as ec
import csv
import json


def get_info():
    links = set()
    user_agent = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36"
    options = webdriver.ChromeOptions()
    options.add_argument(f"user-agent={user_agent}")
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    driver = webdriver.Chrome(options=options)
    url = "https://market.yandex.ru/business--msktv/664406"
    driver.get(url)
    print("got url")
    print("collecting items links")
    while True:
        last_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)  # Пауза для загрузки контента
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

        soup = BeautifulSoup(driver.page_source, 'lxml')
        elements = soup.find_all("a", class_="_20WYq _2nCwp _1gCbc")

        for el in elements:
            link = "https://market.yandex.ru" + el["href"]
            links.add(link)

        try:
            more_button = WebDriverWait(driver, 10).until(
                ec.presence_of_element_located((By.XPATH, '//button[@class="_2AMPZ _1N_0H _1ghok _390_8" and '
                                                          '@type="button" and @data-auto="pager-more"]'))
            )

            more_button.click()
        except TimeoutException:
            break
    return links


def pack_info(links):
    counter = 1
    data = [
        ["Товар", "Цена", "Описание", "Характеристики", "Бренд", "Категория", "Изображения", "Видим"]
    ]
    for link in links:
        driver.get(link)
        time.sleep(3)
        soup1 = BeautifulSoup(driver.page_source, "lxml")
        clas = soup1.find("div", {'data-auto': 'main'})
        if clas:
            element = clas.find('div', {'data-zone-data': True})
            data_dict = json.loads(element["data-zone-data"])
            price = data_dict.get("priceDetails").get("price").replace(" ", "")

            description = soup1.find('div', {'aria-label': 'product-description'}).text.replace('\n', ' ')
            characteristics = soup1.find('div', {'aria-label': 'Характеристики'})
            char_data = characteristics.find_all("div", class_="_198Aj cXkP_ _3wss4")

            title = soup1.find("h1", {"data-auto": "productCardTitle"}).text

            elements = soup1.find_all('span', {'itemprop': 'name', 'class': ['_2fHfr', 'D7c4V', '_3aPfw', '_25vcL']})

            category = elements[-2].text
            brand = elements[-1].text

            try:
                button = driver.find_element(By.CSS_SELECTOR, 'button[data-auto="image-gallery-more"]')
                button.click()
            except Exception:
                continue

            img_tags = soup1.find_all('img', class_='_2gUfn')
            image_links = [img['src'] for img in img_tags]
            links_string = ', '.join(image_links)

            result = []
            result_string = ""
            for i in char_data:
                spans = i.find_all("span")
                string = ': '.join([span.text for span in spans])
                result.append(string)
                result_string = ", ".join(result)
            print(f"## {counter} / {len(links)} done")
            data.append([title, price, description, result_string, brand, category, links_string, 1])
            counter += 1
        else:
            print(f"no clas module for {link}")
    with open("yandex.csv", "w", newline="", encoding="cp1251", errors='replace') as file:
        writer = csv.writer(file, delimiter=';', quotechar='"', quoting=csv.QUOTE_ALL)
        writer.writerows(data)
        print("wrote csv")


def upload():
    url = "https://admin:admin2@mobox-shop.ru/simpla/index.php?module=ImportAdmin"
    driver = webdriver.Chrome()
    driver.get(url)
    file_input = driver.find_element(By.CSS_SELECTOR, 'input.import_file')

    file_path = '/home/mio-welt/PycharmProjects/DA_BIGGAST_PAASA/yandex.csv'
    file_input.send_keys(file_path)
    time.sleep(2)

    upload_button = driver.find_element(By.CSS_SELECTOR, 'input.button_green')
    upload_button.click()
    time.sleep(10)


def main():
    #links = get_info()
    #pack_info(links)
    upload()


if __name__ == "__main__":
    main()
